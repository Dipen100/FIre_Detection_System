{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36a7cc7-13dc-4ac4-bbc0-f2403e5801e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow==2.9.1\n",
      "  Downloading tensorflow-2.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/511.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:04:57\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.9.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441ffcd3-608a-410b-bb15-dbc69b17136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import system libs\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import pathlib\n",
    "import itertools\n",
    "from PIL import Image\n",
    "\n",
    "# import data handling tools\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "#sns.set_style('darkgrid')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# import Deep learning Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print ('modules loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94155447-200d-4197-9292-76bcc9abde5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'Train'\n",
    "filepaths = []\n",
    "labels = []\n",
    "\n",
    "folds = os.listdir(train_dir)\n",
    "for fold in folds:\n",
    "    foldpath = os.path.join(train_dir, fold)\n",
    "    filelist = os.listdir(foldpath)\n",
    "    for file in filelist:\n",
    "        fpath = os.path.join(foldpath, file)\n",
    "        filepaths.append(fpath)\n",
    "        labels.append(fold)\n",
    "\n",
    "# Concatenate data paths with labels into one dataframe\n",
    "Fseries = pd.Series(filepaths, name= 'filepaths')\n",
    "Lseries = pd.Series(labels, name='labels')\n",
    "train_df = pd.concat([Fseries, Lseries], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d6968e-e629-4ba6-b1f6-a1b79119b7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c88e3d9-b867-4fd6-af15-a54e56b7dee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dir = 'Vali'\n",
    "filepaths = []\n",
    "labels = []\n",
    "\n",
    "folds = os.listdir(train_dir)\n",
    "for fold in folds:\n",
    "    foldpath = os.path.join(train_dir, fold)\n",
    "    filelist = os.listdir(foldpath)\n",
    "    for file in filelist:\n",
    "        fpath = os.path.join(foldpath, file)\n",
    "        filepaths.append(fpath)\n",
    "        labels.append(fold)\n",
    "\n",
    "# Concatenate data paths with labels into one dataframe\n",
    "Fseries = pd.Series(filepaths, name= 'filepaths')\n",
    "Lseries = pd.Series(labels, name='labels')\n",
    "valid_df = pd.concat([Fseries, Lseries], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2e3464-9b4c-44e1-9dc4-424c7c896fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b24dcf9-8dea-4c1d-80df-84a73f094b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate  test data paths with labels\n",
    "test_dir = 'Test'\n",
    "filepaths = []\n",
    "labels = []\n",
    "\n",
    "folds = os.listdir(test_dir)\n",
    "for fold in folds:\n",
    "    foldpath = os.path.join(test_dir, fold)\n",
    "    filelist = os.listdir(foldpath)\n",
    "    for file in filelist:\n",
    "        fpath = os.path.join(foldpath, file)\n",
    "        filepaths.append(fpath)\n",
    "        labels.append(fold)\n",
    "\n",
    "# Concatenate data paths with labels into one dataframe\n",
    "Fseries = pd.Series(filepaths, name= 'filepaths')\n",
    "Lseries = pd.Series(labels, name='labels')\n",
    "test_df = pd.concat([Fseries, Lseries], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb4496b-a6a6-42fd-aef6-7ccdb1346952",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0784ae2f",
   "metadata": {},
   "source": [
    "### create image data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3610f34-fe66-4cab-bae2-9afc62b31963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crobed image size\n",
    "batch_size = 16\n",
    "img_size = (224, 224)\n",
    "channels = 3\n",
    "img_shape = (img_size[0], img_size[1], channels)\n",
    "\n",
    "tr_gen = ImageDataGenerator()\n",
    "ts_gen = ImageDataGenerator()\n",
    "train_gen = tr_gen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
    "                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n",
    "\n",
    "valid_gen = ts_gen.flow_from_dataframe( valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
    "                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n",
    "\n",
    "test_gen = ts_gen.flow_from_dataframe( test_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
    "                                    color_mode= 'rgb', shuffle= False, batch_size= batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc09df14-dd79-4767-8127-37c3ff7f494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_dict = train_gen.class_indices      # defines dictionary {'class': index}\n",
    "classes = list(g_dict.keys())       # defines list of dictionary's kays (classes), classes names : string\n",
    "images, labels = next(train_gen)      # get a batch size samples from the generator\n",
    "\n",
    "plt.figure(figsize= (20, 20))\n",
    "\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    image = images[i] / 255       # scales data to range (0 - 255)\n",
    "    plt.imshow(image)\n",
    "    index = np.argmax(labels[i])  # get image index\n",
    "    class_name = classes[index]   # get class of image\n",
    "    plt.title(class_name, color= 'blue', fontsize= 12)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afc0524-ae70-4ccb-a5ca-9f0093de0037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model Structure\n",
    "img_size = (224, 224)\n",
    "channels = 3\n",
    "img_shape = (img_size[0], img_size[1], channels)\n",
    "class_count = len(list(train_gen.class_indices.keys())) # to define number of classes in dense layer\n",
    "\n",
    "# create pre-trained model (you can built on pretrained model such as :  efficientnet, VGG , Resnet )\n",
    "# we will use efficientnetb3 from EfficientNet family.\n",
    "base_model = tf.keras.applications.resnet50.ResNet50(include_top= False, weights= \"imagenet\", input_shape= img_shape, pooling= 'max')\n",
    "# base_model.trainable = False\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001),\n",
    "    Dense(256, kernel_regularizer= regularizers.l2(l= 0.016), activity_regularizer= regularizers.l1(0.006),\n",
    "                bias_regularizer= regularizers.l1(0.006), activation= 'relu'),\n",
    "    Dropout(rate= 0.45, seed= 123),\n",
    "    Dense(class_count, activation= 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4062d69f-ef63-44c1-8453-8805c61a171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20   # set batch size for training\n",
    "epochs =  20  # number of all epochs in training\n",
    "\n",
    "history = model.fit(x= train_gen, epochs= epochs, verbose= 1, validation_data= valid_gen, \n",
    "                    validation_steps= None, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0089c77-a71e-4f9f-8f04-7927c9429be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define needed variables\n",
    "tr_acc = history.history['accuracy']\n",
    "tr_loss = history.history['loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "index_loss = np.argmin(val_loss)\n",
    "val_lowest = val_loss[index_loss]\n",
    "index_acc = np.argmax(val_acc)\n",
    "acc_highest = val_acc[index_acc]\n",
    "Epochs = [i+1 for i in range(len(tr_acc))]\n",
    "loss_label = f'best epoch= {str(index_loss + 1)}'\n",
    "acc_label = f'best epoch= {str(index_acc + 1)}'\n",
    "# Plot training history\n",
    "plt.figure(figsize= (20, 8))\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
    "plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
    "plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n",
    "plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n",
    "plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b5cb99-dbb9-4907-8375-1131424e2a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_length = len(test_df)\n",
    "test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n",
    "test_steps = ts_length // test_batch_size\n",
    "\n",
    "train_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\n",
    "valid_score = model.evaluate(valid_gen, steps= test_steps, verbose= 1)\n",
    "test_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n",
    "\n",
    "print(\"Train Loss: \", train_score[0])\n",
    "print(\"Train Accuracy: \", train_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Validation Loss: \", valid_score[0])\n",
    "print(\"Validation Accuracy: \", valid_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Test Loss: \", test_score[0])\n",
    "print(\"Test Accuracy: \", test_score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b16eb38-bdd6-4dc2-b00e-c02a6905b724",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_generator(test_gen)\n",
    "y_pred = np.argmax(preds, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9317ef-6a74-411d-9c1b-838c640ed9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_dict = test_gen.class_indices\n",
    "classes = list(g_dict.keys())\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_gen.classes, y_pred)\n",
    "\n",
    "plt.figure(figsize= (10, 10))\n",
    "plt.imshow(cm, interpolation= 'nearest', cmap= plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation= 45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b4c887-82ae-4564-9616-f7162733a332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(classification_report(test_gen.classes, y_pred, target_names= classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e82e58-3438-414a-ab76-d56cd4edb354",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "model.save('resnetmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f7fdd5-6252-4541-bfcc-095b2273da13",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('resnetmodel.h5', compile=False)\n",
    "loaded_model.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8600ff25-dd59-4d39-afb2-80eda6ab4bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'Test/Fire/SynDay101.jpg'\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Preprocess the image\n",
    "img = image.resize((224, 224))\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "# Make predictions\n",
    "predictions = loaded_model.predict(img_array)\n",
    "class_labels = classes\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "print(f\"{class_labels[tf.argmax(score)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b798e51c-02bd-4816-b447-957bbc64ce8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'Vali/Non-Fire/crash165.jpg'\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Preprocess the image\n",
    "img = image.resize((224, 224))\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "# Make predictions\n",
    "predictions = loaded_model.predict(img_array)\n",
    "class_labels = classes\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "print(f\"{class_labels[tf.argmax(score)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f3fd11-6884-4ecd-93ac-6d88f262cd42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
